{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc141d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random weights shape: (4, 3)\n",
      "[[0.19345059 0.60766925 0.20824328]\n",
      " [0.31627351 0.79991851 0.54929838]\n",
      " [0.26063442 0.13703967 0.34359184]\n",
      " [0.22606951 0.9341868  0.21422426]]\n",
      "Random inputs shape: (4,)\n",
      "Random inputs shape transponse (4,)\n",
      "[0.33027158 0.05187004 0.43370551 0.46907143]\n",
      "Random biases shape: (3,)\n",
      "[0.56986068 0.40977493 0.70589063]\n",
      "Front propagation results: \n",
      "[0.86923837 1.14959782 1.05266375]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "Iris classification based on provided data\n",
    "Author: PaweÅ‚ Kozikowski\n",
    "\"\"\"\n",
    "\n",
    "NEURAL_NETWORK_DATABASE: str = 'weights.npz'\n",
    "IRIS_DATABASE: str = 'Iris.csv'\n",
    "\n",
    "def sigmoid(value):\n",
    "      return ((1 / (1 + (np.exp(-value)))))\n",
    "def sigmoid_derivative(value):\n",
    "      return ((np.exp(-value) / ((1 + np.exp(-value)) ** 2)))\n",
    "\n",
    "def read_csv_data(csv_file: str) -> list[dict]:\n",
    "      df = pd.read_csv(os.path.abspath(csv_file))\n",
    "      df_format_to_dict: list[dict] = df.to_dict(orient=\"records\")\n",
    "      \n",
    "      return df_format_to_dict\n",
    "\n",
    "def format_csv_data(csv_data: dict) -> list[tuple[np.ndarray, np.ndarray]]:\n",
    "      formatted_data_array: list[tuple[np.ndarray, np.ndarray]] = []\n",
    "      \n",
    "      for data_pack in csv_data:\n",
    "            input_matrix: np.ndarray = np.array([\n",
    "                  np.float64(data_pack[\"SepalLengthCm\"]),\n",
    "                  np.float64(data_pack[\"SepalWidthCm\"]),\n",
    "                  np.float64(data_pack[\"PetalLengthCm\"]),\n",
    "                  np.float64(data_pack[\"PetalWidthCm\"])\n",
    "            ])\n",
    "            \n",
    "            label_matrix: np.ndarray = np.array([])\n",
    "\n",
    "            if (data_pack[\"Species\"] == \"Iris-setosa\"):\n",
    "                  label_matrix = np.array([1, 0, 0])\n",
    "            elif (data_pack[\"Species\"] == \"Iris-versicolor\"):\n",
    "                  label_matrix = np.array([0, 1, 0])\n",
    "            elif (data_pack[\"Species\"] == \"Iris-virginica\"):\n",
    "                  label_matrix = np.array([0, 0, 1])\n",
    "\n",
    "            tupled_data: tuple[np.ndarray, np.ndarray] = (input_matrix, label_matrix)\n",
    "            formatted_data_array.append(tupled_data)\n",
    "      \n",
    "      return formatted_data_array\n",
    "\n",
    "def save_neural_network_parameters(npz_file: str, parameters: tuple[np.ndarray, np.ndarray]) -> None:\n",
    "      \"\"\"\n",
    "      save_neural_network_parameters FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            npz_file: NPZ file where neural network`s data such as weights and biases will be stored\n",
    "            parameters: Neural network`s data such as weights and biases that will be stored\n",
    "      \n",
    "      Returns:\n",
    "            None\n",
    "\n",
    "      Purpose:\n",
    "            Saving newly calculated data about out neural network such as weights and biases to proper NPZ file\n",
    "      \"\"\"\n",
    "      # Separation data on weights and biases\n",
    "      new_weights: np.ndarray = parameters[0]\n",
    "      new_biases: np.ndarray = parameters[1]\n",
    "      \n",
    "      # Saving data to provided NPZ file\n",
    "      np.savez(npz_file, \n",
    "               weights=new_weights,\n",
    "               biases=new_biases)\n",
    "      \n",
    "      return None\n",
    "\n",
    "def load_neural_network_parameters(npz_file: str) -> tuple[np.ndarray, np.ndarray]:\n",
    "      \"\"\"\n",
    "      load_neural_network_parameters FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            npz_file: NPZ file containg data about current weights and biases\n",
    "\n",
    "      Returns:\n",
    "            loaded_weights, loaded_biases\n",
    "            Tuple containg current weights and biases of neural network\n",
    "      \n",
    "      Purpose:\n",
    "            Loads data from proper database to use it in other algorithms\n",
    "      \"\"\"\n",
    "      # Read data from NPZ file\n",
    "      loaded_neural_network_data = np.load(npz_file)\n",
    "\n",
    "      # Loads weights and biases from this file\n",
    "      loaded_weights: np.ndarray = loaded_neural_network_data[\"weights\"]\n",
    "      loaded_biases: np.ndarray = loaded_neural_network_data[\"biases\"]\n",
    "\n",
    "      return loaded_weights, loaded_biases\n",
    "\n",
    "def front_propagation(input_matrix: np.ndarray, weights_matrix: np.ndarray, biases_matrix: np.ndarray) -> np.ndarray:\n",
    "      \"\"\"\n",
    "      front_propagation FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            input_matrix: Matrix containing input values for our neural network\n",
    "            weights_matrix: Matrix containing weights values of our neural network\n",
    "            biases_matrix: Matrix containing biases values for our neural network\n",
    "\n",
    "      Returns:\n",
    "            linear_output: Matrix containing pre activation sums on each neuron in our output layer\n",
    "\n",
    "      Purpose:\n",
    "            Front propagation algorithm calculate pre activation sum on each neuron in our output layer\n",
    "            This sum after transforming by activation function can be readed as value representing which answer is most likely to be true\n",
    "      \"\"\"\n",
    "      # Calculating Matrix containing pre activation sums on each neuron in output layer\n",
    "      linear_output = input_matrix @ weights_matrix + biases_matrix\n",
    "\n",
    "      return linear_output\n",
    "\n",
    "def back_propagation(input_matrix: np.ndarray, sums_matrix: np.ndarray, target_matrix: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "      \"\"\"\n",
    "      back_propagation FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            input_matrix: Matrix containing input values for our neural network\n",
    "            sums_matrix: Matrix contating pre activation values for neurons in our output layer\n",
    "            target_matrix: Matrix containg prepared target values informing which answer is correct\n",
    "\n",
    "      Returns:\n",
    "            gradient_weights_matrix, gradient_bias_matrix\n",
    "            Tuple containing gradients of weights and biases that are needed to be applied to current weights and biases\n",
    "            in order to make our neural network \"more intelligent\"\n",
    "\n",
    "      Purpose:\n",
    "            Back propagation algorithm enables our neural network to be more intelligent after each contact with data\n",
    "            By this algorithm weights and biases in our neural network are being more and more appropriate to inputs we deliver\n",
    "            to input layer of our neural network\n",
    "      \"\"\"\n",
    "      # Calculate post activation outputs of our neural network\n",
    "      sigmoid_matrix: np.ndarray = sigmoid(sums_matrix)\n",
    "      \n",
    "      # Calculating final output value for output layer\n",
    "      error_signal = 2 * (sigmoid_matrix - target_matrix)\n",
    "      sigmoid_derivative_matrix = sigmoid_matrix * (1 - sigmoid_matrix) # Optimized version for calculating sigmoid derivative\n",
    "      delta_layer = error_signal * sigmoid_derivative_matrix\n",
    "      \n",
    "      # Calculating weights gradient with use of outer multiplication\n",
    "      gradient_weights_matrix: np.ndarray = np.outer(input_matrix, delta_layer)\n",
    "      \n",
    "      # Calculating biases gradient (delta_layer can be assigned)\n",
    "      gradient_bias_matrix: np.ndarray = delta_layer\n",
    "\n",
    "      return gradient_weights_matrix, gradient_bias_matrix\n",
    "      \n",
    "def single_train(input_matrix: np.ndarray, target_matrix: np.ndarray, learning_rate: np.float64 = 0.1) -> None:\n",
    "      \"\"\"\n",
    "      single_train FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            input_matrix: Matrix containg input values for our neural network\n",
    "            target_matrix: Matrix containg prepared target values informing which answer is correct\n",
    "            learning_rate: Rate with which our neural network learns (Can be interpreted as jump in looking for minimum in our cost function)\n",
    "\n",
    "      Returns:\n",
    "            None\n",
    "\n",
    "      Purpose:\n",
    "            Adjust weights and biases of our Neural Network to perform better at presenting us correct answers\n",
    "      \"\"\" \n",
    "      # Load current weights and biases of our neural network\n",
    "      weights_matrix, biases_matrix = load_neural_network_parameters(NEURAL_NETWORK_DATABASE)\n",
    "      # Front propagation\n",
    "      sums_matrix: np.ndarray = front_propagation(input_matrix, weights_matrix, biases_matrix)\n",
    "      \n",
    "      # Back propagation\n",
    "      weights_gradient, biases_gradient = back_propagation(input_matrix, sums_matrix, target_matrix)\n",
    "      # Calculating new weights and biases for our neural network\n",
    "      new_weights_matrix: np.ndarray = weights_matrix - learning_rate * weights_gradient\n",
    "      new_biases_matrix: np.ndarray = biases_matrix - learning_rate * biases_gradient\n",
    "\n",
    "      # Saving new data in database\n",
    "      save_neural_network_parameters(NEURAL_NETWORK_DATABASE, (new_weights_matrix, new_biases_matrix))\n",
    "\n",
    "      return None\n",
    "\n",
    "def init_parameters(input_size: int, output_size: int) -> None:\n",
    "      \"\"\"\n",
    "      init_paramaters FUNCTION\n",
    "\n",
    "      Parameters:\n",
    "            input_size: Size of input layer in our neural network\n",
    "            output_size: Size of output layer in our neural network\n",
    "\n",
    "      Returns:\n",
    "            None\n",
    "      \n",
    "      Purpose:\n",
    "            Our Neural Network need to be initialized with random weights and biases to actually change them and learn with each portion of data\n",
    "      \"\"\"\n",
    "      # Initializing random weights of our neural network\n",
    "      initialized_weights = np.random.rand(input_size, output_size)\n",
    "      # Initializing random biases of our neural network\n",
    "      initialized_biases = np.zeros(output_size)\n",
    "\n",
    "      # Saving new weights and biases to provided database\n",
    "      save_neural_network_parameters(NEURAL_NETWORK_DATABASE, (initialized_weights, initialized_biases))\n",
    "\n",
    "      return None\n",
    "\n",
    "def train_network(epochs: int, learning_rate: np.float64 = 0.1) -> None:\n",
    "      \"\"\"\n",
    "      train_network FUNCTION\n",
    "\n",
    "      Paramaters:\n",
    "            epochs: Number of epchos user provide for our neural network\n",
    "            What is epochs ? \n",
    "            Epochs is one training serie for our neural network in which all provieded data is propagated through our neural network\n",
    "      \n",
    "      Returns:\n",
    "            None\n",
    "\n",
    "      Purpose:\n",
    "            This function enables our neural network to work and learn on big database.\n",
    "            Each epchos makes our neural network \"smarter\" by adjusting each weight and bias\n",
    "      \"\"\"\n",
    "      # Reading CSV data from Iris Database \n",
    "      iris_csv_data: list[dict] = read_csv_data(IRIS_DATABASE)\n",
    "      # Formtting iris_csv_data\n",
    "      formatted_iris_database: list[tuple[np.ndarray, np.ndarray]] = format_csv_data(iris_csv_data)\n",
    "\n",
    "      # Loop which trains \n",
    "      for epoch in range(epochs):\n",
    "            for input_matrix, target_matrix in formatted_iris_database:\n",
    "                  # Do single training session\n",
    "                  single_train(input_matrix, target_matrix, learning_rate)            \n",
    "\n",
    "      return None\n",
    "\n",
    "def predict(input_matrix: np.ndarray) -> tuple[str, np.ndarray]:\n",
    "      \"\"\"\n",
    "      predict FUNCTION\n",
    "\n",
    "      Paramters:\n",
    "            input_matrix: Matrix containing inputs values for our neural network\n",
    "      \n",
    "      Returns:\n",
    "            Name of predicted Iris type and matrix containg values of each neuron output\n",
    "      \n",
    "      Purpose:\n",
    "            This function make predictions from inputs provided by user.\n",
    "            Inputs matrix contains data about Iris characteristic such as\n",
    "            1. Sepal Length \n",
    "            2. Sepal Width\n",
    "            3. Petal Length\n",
    "            4. Petal Width\n",
    "      \"\"\"\n",
    "      # Loading current weights and biases of our neural network\n",
    "      weights, biases = load_neural_network_parameters(NEURAL_NETWORK_DATABASE)\n",
    "      # Calculating pre activation sums on each neuron based on loaded weight biases and provided input matrix\n",
    "      sums = front_propagation(input_matrix, weights, biases)\n",
    "      # Calculating post activation sums on each neuron\n",
    "      outputs = sigmoid(sums)\n",
    "\n",
    "      # Choosing index of matrix with largest value\n",
    "      predicted_class_index = np.argmax(outputs)\n",
    "      # Mapping answers for model to provide\n",
    "      species: list[str] = [\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"] \n",
    "\n",
    "      return species[predicted_class_index], outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
